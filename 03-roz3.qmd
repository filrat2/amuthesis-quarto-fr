---
editor: 
  markdown: 
    wrap: sentence
---

# Materiały {#sec-materialy}

## Zdjęcia satelitarne {#sec-satellite-imagery}

### Sentinel-1 {#sec-sentinel1}


### Senitnel-2 {#sec-sentinel2}
Misja Sentinel-2 stanowi inicjatywę Komisji Europejskiej, która jest operacyjnie prowadzona przez Europejską Agencję Kosmiczną (ang. *European Space Agency*, ESA) w ramach programu Copernicus.
Celem tej misji jest dostarczanie obrazów satelitarnych, obejmujących trzynaście zakresów spektralnych o różnych rozdzielczościach przestrzennych: 10, 20 lub 60 metrów, zależnie od rejestrowanego kanału.
Rozdzielczość czasowa misji Sentinel-2 wynosi pięć dni nad równikiem i zwiększa się wraz ze wzrostem szerokości geograficznej, osiągając dwa dni na średnich szerokościach geograficznych [@hejmanowska_2020_dane].

Dane pozyskiwane przez satelity Sentinel-2 są dostępne na różnych poziomach przetworzenia, lecz najczęściej używane przy tworzeniu map pokrycia terenu i użytkowania ziemi (ang. *Land Use/Land Cover*, LULC) są produkty 1C (współczynnik odbicia na poziomie górnej części atmosfery; ang. *Top-of-Atmospheric reflectance*, TOA) oraz 2A (współczynnik odbicia na powierzchni Ziemi; ang. *Bottom-of-Atmospheric reflectance*, BOA) [@phiri_2020_sentinel2].

Produkty poziomu 1C to dane poddane korekcjom radiometrycznym i geometrycznym, prezentowane jako sceny o powierzchni 100 km^2^ (100 x 100 km) w projekcji UTM/WGS84 [@esa_2015_sentinel2handbook].
Skuteczne wykorzystanie tych danych w zastosowaniach związanych z terenami lądowymi wymaga precyzyjnej korekcji zdjęć satelitarnych pod kątem efektów atmosferycznych [@main-knorn_2017_Sen2Cor].
Produkty poziomu 2A powstają poprzez zastosowanie dodatkowej korekcji atmosferycznej dla danych poziomu 1C za pomocą procesora korekcji atmosferycznej Sen2Cor [@main-knorn_2017_Sen2Cor].

```{r tabela1, echo=FALSE}
#| label: tbl-tabela1
#| echo: false
#| tbl-cap: "Kanały spektralne satelitów Sentinel-2"
df = data.frame(
  a = c("B01","B02","B03","B04","B05","B06","B07","B08","B8A","B09","B10","B11","B12"),
  b = c("Coastal Aerosol","Blue","Green","Red","Vegetation RedEdge","Vegetation RedEdge","Vegetation RedEdge","NIR","NIR","Water Vapour","Cirrus","SWIR","SWIR"),
  c = c(443,490,560,665,705,740,783,842,865,945,1375,1610,2190),
  d = c("433–453","458–523","543–578","650–680","698–713","733–748","773–793","785–900","855–875","935–955","1360–1390","1565–1655","2100–2280"),
  e = c(60,10,10,10,20,20,20,10,20,60,60,20,20)
)
colnames(df) = c("Kanał", "Nazwa kanału", "Centralna długość fali [nm]", "Zakres spektralny [nm]", "Rozdzielczość przestrzenna [m]")
knitr::kable(df, booktabs = TRUE) |> 
  kableExtra::column_spec(1, width = "1.5cm") |>  
  kableExtra::column_spec(2, width = "4cm") |>
  kableExtra::column_spec(3, width = "2cm") |> 
  kableExtra::column_spec(4, width = "2cm") |> 
  kableExtra::column_spec(5, width = "2cm")
```

Z dostępnych kanałów spektralnych (Tabela [-@tbl-tabela1]) wykorzystano 10 zakresów, ponieważ pasma rejestrowane w rozdzielczości 60 metrów są przeznaczone głównie do korekcji atmosferycznych i detekcji chmur. Kanał 1 (443 nm) służy do korekcji wpływu aerozoli, kanał 9 (940 nm) do korekcji wpływu pary wodnej, a kanał 10 (1375 nm) do wykrywania chmur typu cirrus [@drusch_2012_sen2GMES].

### Indeksy spektralne - ???

### Tekstury obrazu - ???

## Ortofotomapa i mozaiki zdjęć satelitarnych {#sec-mosaics}

Do lokalizacji oraz wektoryzacji istniejących farm fotowoltaicznych wykorzystano ortofotomapę udostępnianą przez Główny Urząd Geodezji i Kartografii oraz mozaiki zdjęć satelitarnych dostarczane przez podmioty komercyjne.
W teledetekcji jednym z zastosowań mozaik obrazów satelitarnych jest tworzenie zestawów danych referencyjnych poprzez interpretację wizualną, np. w celu walidacji wyników klasyfikacji produktów pokrycia terenu [@lesiv_2018_sat_imagery_mosaics]. 
Do stworzenie zbioru danych testowych i treningowych wykorzystano ortomozaiki Google Satellite, Bing Aerial, Mapbox Satellite oraz Planet Basemaps, udostępniane w formie usług sieciowych (WMS, WMTS, XYZ Tiles).
Ortomozaiki te są tworzone na podstawie komercyjnych zdjęć satelitarnych wykonywanych przez podmioty takie jak Maxar Technologies, Airbus czy Planet Labs.
Ortofotomapa udostępniana przez GUGiK charakteryzuje się rozdzielczością przestrzenną 25 cm, a rozdzielczość przestrzenna wykorzystanych mozaik obrazów satelitarnych (poza Planet Basemaps) jest wyższa niż 1 m, np. dla mozaiki Bing Aerial udostępnianej przez firmę Microsoft wynosi ona 30-60 cm.
Często jednak nie jest możliwie ustalenie dat wykonania zdjęć satelitarnych, które posłużyły do stworzenia konkretnej mozaiki zobrazowań satelitarnych [@lesiv_2018_sat_imagery_mosaics]. 
Mozaika tworzona przez Planet na podstawie zdjęć satelitarnych wykonywanych przez konstelację satelitów PlanetScope charakteryzuje się rozdzielczością przestrzenną 4,77 m na równiku, jednak w porównaniu do pozostałych wymienionych produktów jest tworzona z miesięczną oraz kwartalną częstotliwością. Pozwala to, pomimo niższej rozdzielczości przestrzennej na stworzenie zbioru danych testowych i treningowych na konkretny okres czasu [@planet-basemaps-product-specifications.pdf].
Mozaiki Planet Basemaps są tworzone na podstawie zdjęć wybieranych przy użyciu algorytmu, który wybiera najlepsze obrazy z katalogu Planet w określonym przedziale czasowym. Wybierając najlepsze obrazy, Planet jest w stanie tworzyć wysokorodzielcze mozaiki, które są dokładne radiometrycznie i przestrzennie, a także charakteryzują się zminimalizowanym wpływem czynników atmosferycznych[@planet-basemaps-product-specifications.pdf???].

?Rycina przedstawiająca jedną farmę na ortofotomapie, mozaikach satelitarnych i scenie Sentinel-2 (kompozycja RGB)

## Przygotowanie danych {#sec-processing}

Resampling kanałów w rozdzielczości 20 m do 10 m (metoda=bilinear).
Złączenie kanałów w wielokanałowy raster.
Opisać pozostałe czynności wykonane z tymi danymi.

?rycina - schemat przygotowania danych
?rycina - workflow Sentinel-1

## Próbki treningowe i testowe {#sec-samples}

## Uczenie maszynowe {#sec-machine-learning}

Klasyfikacja obrazów w teledetekcji polega na grupowaniu komórek w niewielkie zestawy klas, aby komórki w tych samych klasach miały podobne właściwości [@ismail_2009_classification].
Istnieje wiele różnych metod klasyfikacji danych teledetekcyjnych.
Stosunkowo nowymi podejściami wykorzystywanymi w tym kontekście są metody oparte na sztucznej inteligencji, takie jak uczenie maszynowe (ang. *Machine Learning*, ML) lub uczenie głębokie (ang. *Deep Learning*, DL) [@hejmanowska_2020_dane].

Uczenie maszynowe stanowi obszar sztucznej inteligencji, koncentrujący się na opracowywaniu algorytmów i modeli statystycznych zapewniających systemom komputerowym możliwość automatycznego uczenia się z danych i wykonywania określonych zadań bez konieczności bezpośredniego programowania. 
W przypadku skomplikowanych i złożonych zestawów danych nie jesteśmy w stanie odpowiednio ich zinterpretować oraz wydobyć poprawnych informacji po wizualnym przejrzeniu danych [@mahesh_2019_ml].
Uczenie maszynowe jest wykorzystywane do uczenia maszyn efektywnego przetwarzania danych [@sindayigaya_2022_ml].
Algorytmy uczenia maszynowego można podzielić na cztery główne podejścia: uczenie nienadzorowane (ang. *unsupervised learning*), uczenie nadzorowane (ang. *supervised learning*), uczenie częściowo nadzorowane (ang. *semi-supervised learning*) oraz uczenie przez wzmacnianie (uczenie posiłkowane, ang. *reinforcement learning*) [@sarker_2021_ml].

W ciągu ostaniach dwudziestu lat zaproponowano kilka różnych algorytmów uczenia maszynowego do klasyfikacji obrazów satelitarnych [@sheykhmousa_2020_svm_vs_rf], zazwyczaj wykorzystujące techniki klasyfikacji bez nadzoru i klasyfikacji nadzorowanej [@ismail_2009_classification].

Uczenie nienadzorowane analizuje nieoznakowane zbiory danych bez konieczności ingerencji człowieka. 
Uczenie bez nadzoru jest powszechnie stosowane do eksploracji danych, ekstrakcji cech generatywnych, identyfikacji istotnych trendów i struktur oraz grupowania wyników.
Ta technika uczenia maszynowego jest najczęściej używana do grupowania (klastowania), redukcji wielowymiarowości (redukcji cech) oraz identyfikacji skojarzeń i relacji [@sarker_2021_ml].

Nadzorowane algorytmy uczenia maszynowego wykorzystują oznaczone dane treningowe do znajdywania powiązań pomiędzy różnymi zmiennymi.
Proces uczenia nadzorowanego zachodzi, gdy określone cele mają zostać osiągnięte na podstawie konkretnego zestawu danych wejściowych (treningowych). Dwa główne typy uczenia nadzorowanego to klasyfikacja, która separuje dane, oraz regresja, która dopasowuje dane [@sarker_2021_ml]. 

W badaniu do klasyfikacji wykorzystano nadzorowaną metodę lasów losowych (ang. *Random Forest*, RF) [@breiman_2001_rf].

### Metoda lasów losowych {#sec-random-forest}

## Środowisko języka R


```{r}
#| label: fig-rycina1
#| echo: false
#| fig-cap: "Moja pierwsza rycina"
plot(1, 4)
```

```{r}
#| label: fig-rycina2
#| echo: false
#| fig-cap: "Moja druga rycina"
#| out-width: "100%"
#| out-height: 300px
knitr::include_graphics("figures/rcookies.png")
```
