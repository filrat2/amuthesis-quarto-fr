% This is a LaTeX thesis template for Adam Mickiewicz University.
% to be used with quarto
% This template was produced by Jakub Nowosad
% Version: 22 July 2023

% Inspired by:
% This is a LaTeX thesis template for Monash University.
% to be used with Rmarkdown
% This template was produced by Rob Hyndman
% Version: 6 September 2016

\documentclass{amuthesis}
% \usepackage[polish]{babel}
\usepackage{polski}
\renewcommand{\figurename}{Rycina} % Redefine default figure caption %
\renewcommand{\tablename}{Tabela} % Redefine default table caption %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Add any LaTeX packages and other preamble here if required
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{booktabs,tabularx} % Allows kableExtra to work %
\usepackage{indentfirst} % Adds indent in the first paragraph %
\usepackage{bookmark} % Adds indent in the first paragraph %

\author{Filip Ratajszczak}
\title{Wykrywanie farm fotowoltaicznych na podstawie danych
teledetekcyjnych}
\def\titleeng{My title}
\def\degreetitle{Praca inżynierska}
\def\major{Geoinformacja}
\def\albumid{461791}
\def\thesisyear{2024}

% Add subject and keywords below
\hypersetup{
     %pdfsubject={The Subject},
     %pdfkeywords={Some Keywords},
     pdfauthor={Filip Ratajszczak},
     pdftitle={Wykrywanie farm fotowoltaicznych na podstawie danych
teledetekcyjnych},
     pdfproducer={quarto with LaTeX}
}

\bibliography{thesis.bib, packages.bib}

\begin{document}

\pagenumbering{arabic}

\titlepage

\bookmarksetup{startatroot}

\hypertarget{streszczenie}{%
\chapter*{Streszczenie}\label{streszczenie}}
\addcontentsline{toc}{chapter}{Streszczenie}

\markboth{Streszczenie}{Streszczenie}

\textbf{Abstrakt}

Streszczenie powinno przedstawiać skrótowo główny problem pracy i jego
rozwiązanie. Możliwa struktura streszczenia to: (1) 1-3 zdania wstępu do
problemu (czym się zajmujemy, dlaczego jest to ważne, jakie są
problemy/luki do wypełnienia), (2) 1 zdanie opisujące cel pracy, (3) 1-3
zdania przedstawiające użyte materiały (dane) i metody (techniki,
narzędzia), (4) 1-3 zdania obrazujące główne wyniki pracy, (5) 1-2
zdania podsumowujące; możliwe jest też określenie dalszych
kroków/planów.

Słowa kluczowe: (4-6 słów/zwrotów opisujących treść pracy, które nie
wystąpiły w tytule)

\textbf{Abstract}

The abstract must be consistent with the above text.

Keywords: (as stated before)

\newpage

\setstretch{1.2}\sf\tighttoc\doublespacing

\bookmarksetup{startatroot}

\hypertarget{sec-wprowadzenie}{%
\chapter{Wprowadzenie}\label{sec-wprowadzenie}}

Wprowadzenie powinno mieć charakter opisu od ogółu do szczegółu (np.
trzy-pięć paragrafów). Pierwszy paragraf powinien być najbardziej
ogólny, a kolejne powinny przybliżać czytelnika do problemu.
Przedostatni paragraf powinien określić jaki jest problem (są problemy),
który praca ma rozwiązać i dlaczego jest to (są one) ważne.

Wprowadzenie powinno być zakończone stwierdzeniem celu pracy. Dodatkowo
tutaj może znaleźć się również krótki opis co zostało zrealizowane w
pracy.

\bookmarksetup{startatroot}

\hypertarget{sec-lit}{%
\chapter{Przegląd literatury}\label{sec-lit}}

Ten rozdział zawiera wyjaśnienie kontekstu pracy.

Pisząc ten rozdział proszę pomyśleć o osobach, które zupełnie nie znają
opisywanej tematyki. Należy tutaj krok po kroku wyjaśnić podstawowe
koncepcje, istotność problemu, wyniki poprzednich podobnych badań, itd.
Ten rozdział obejmuje tylko kwestie, które już zostały wykonane przez
inne osoby - nowe wyniki mają swoje miejsce w rozdziale
\ref{sec-wyniki}.

Każda kwestia opisana w tym rozdziale powinna być cytowana. Dodatnie
cytowania odbywa się poprzez uzupełnienie pliku \texttt{thesis.bib}
zapisem w formacie BibTeX, a następnie dodanie nazwy referencji
poprzedzonej znakiem \texttt{@}. Przykładowo, zacytowanie książki
Geocomputation with R odbywa się poprzez
\autocite{lovelace_geocomputation_2019}.

W przypadku, gdy cytowanie zostało poprawnie wpisane oraz istnieje w
pliku \texttt{thesis.bib} to bibliografia powinna się automatycznie
wygenerować na końcu pracy.

W przypadku, gdy praca dyplomowa opisuje konkretny obszar to można po
tym rozdziale stworzyć kolejny rozdział opisujący ``obszar badań''.

Ten i kolejne rozdziału moją mieć także podrozdziały. Tworzenie
podrozdziałów polega na stworzeniu nowej linii rozpoczynającej się od
znaków \texttt{\#\#} a następnie tytułu podrozdziału. Dodatkowo w
postaci \texttt{\{\#sec-\}} można dodać skrót nazwy
rozdziału/podrozdziału umożliwiający odnoszenie się do niego używając
operatora \texttt{{[}-@sec{]}}.

\hypertarget{sec-podr}{%
\section{Podrozdział}\label{sec-podr}}

Przykładowo, ``te kwestie zostały opisane w podrozdziale
\ref{sec-podr}''. Zwróć uwagę, że w ten sposób automatycznie tworzony
jest odnośnik w pliku PDF.

\bookmarksetup{startatroot}

\hypertarget{sec-materialy}{%
\chapter{Materiały}\label{sec-materialy}}

\hypertarget{sec-satellite-imagery}{%
\section{Zdjęcia satelitarne}\label{sec-satellite-imagery}}

\hypertarget{sec-sentinel1}{%
\subsection{Sentinel-1}\label{sec-sentinel1}}

Misja Sentinel-1 stanowi Europejskie Obserwatorium Radarowe działające w
ramach programu Copernicus, wspólnej inicjatywy Komisji Europejskiej i
Europejskiej Agencji Kosmicznej \autocite{sentinel1_overview}. Celem
misji jest dostarczanie danych radarowych obejmujących globalną
powierzchnię Ziemi, w tym lądów, europejskich stref przybrzeżnych, tras
żeglugowych, stref lodu morskiego, mórz i oceanów
\autocite{hejmanowska_2020_dane,sentinel1_mission_objectives}. Misja
odpowiada na potrzeby monitorowania obszarów morskich i lądowych, w tym
przemieszczania kry lodowej, transportu morskiego, deformacji i
przemieszczeń terenu, a także obserwacji zmian klimatu i klęsk
żywiołowych
\autocite{hejmanowska_2020_dane,sentinel1_mission_objectives}.

Sentinel-1 jest wyposażony w radar z syntetyczną aperturą (ang.
\emph{Synthetic Aperture Radar}, SAR), pracujący w paśmie C na
częstotliwości 5,405 GHz, co odpowiada długości fali 5,6 cm
\autocite{sentinel1_lulc,sentinel1_instrument_payload}. Radar działa
głównie w trybie podwójnej polaryzacji, emitując fale pionowe i mierząc
zarówno fale pionowe (ang. \emph{vertical}), jak i poziome (ang.
\emph{horizontal}) po ich powrocie do czujnika, dzięki czemu otrzymujemy
dane o intensywności rozproszenia wstecznego VV i VH
\autocite{sentinel1_lulc}. Radar z syntetyczną aperturą (SAR) umożliwia
prowadzenie obserwacji zarówno w nocy, jak i w dzień, niezależnie od
warunków pogodowych, przez co czas między rejestracją obrazów dla
pojedynczego satelity Sentinel-1 wynosi 12 dni nad równikiem, a dla
konstelacji dwóch satelitów skraca się do od dwóch do sześciu dni,
zależnie od szerokości geograficznej
\autocite{hejmanowska_2020_dane,sentinel1_overview}.

Dane radarowe Sentinel-1 sa dostępne na trzech poziomach przetworzenia.
Produkty poziomu 1 (Single Look Complex (SLC) i Ground Range Detected
(GRD)), są przeznaczone dla użytkowników końcowych i nadają się, w
zależności od produktu do do monitorowania Ziemi, klasyfikacji pokrycia
terenu czy aplikacji interferometrycznych
\autocite{hejmanowska_2020_dane}. SLC to obrazy SAR w geometrii ukośnej,
zachowujące informację fazową sygnału \autocite{hejmanowska_2020_dane}.
Produkty GRD są rezultatem przepróbkowania obrazów SLC do jednolitej
rozdzielczości przestrzennej (10 × 10 m) i rzutowania na powierzchnię
elipsoidy odniesienia \autocite{hejmanowska_2020_dane}. GRD nie zawiera
cech ortofotomapy i wymaga dodatkowego przepróbkowania z użyciem
numerycznego modelu terenu przed zastosowaniem w systemach GIS
\autocite{hejmanowska_2020_dane}. Przy konwersji SLC do GRD tracimy
informację fazową sygnału, co sprawia, że produkty GRD nie są
odpowiednie do interferometrii radarowej \autocite{sentinel1_products}.

Dane Sentinel-1 rejestrowane są w czterech trybach: Interferometric Wide
Swath (IW) -- podstawowy tryb obrazowania dla obszarów lądowych,
Stripmap (SM) -- używany do obrazowania małych wysp i na potrzeby
zarządzania kryzysowego, Extra-Wide Swath (EW) -- tryb do monitorowania
stref polarnych i niektórych obszarów morskich, Wave (WV) -- tryb
obrazowania oceanów
\autocite{hejmanowska_2020_dane,sentinel1_instrument_payload,sentinel1_stripmap}.

Dane wykorzystane do analizy pochodzą z produktów Ground Range Detected
(GRD) zarejestrowanych w trybie Interferometric Wide Swath (IW) przez
satelitę Sentinel-1B w dniu 8 maja 2023 roku. Zestaw danych został
utworzony poprzez połączenie dwóch sąsiednich produktów Sentinel-1 GRD,
a następnie ograniczenie obszaru analizy do kafla Sentinel-2 o
oznaczeniu 33UWV. W analizie uwzględniono dwie polaryzacje: VV i VH.

\hypertarget{sec-sentinel2}{%
\subsection{Senitnel-2}\label{sec-sentinel2}}

Misja Sentinel-2 stanowi inicjatywę Komisji Europejskiej, która jest
operacyjnie prowadzona przez Europejską Agencję Kosmiczną (ang.
\emph{European Space Agency}, ESA) w ramach programu Copernicus. Celem
tej misji jest dostarczanie obrazów satelitarnych, obejmujących
trzynaście zakresów spektralnych o różnych rozdzielczościach
przestrzennych: 10, 20 lub 60 metrów, zależnie od rejestrowanego kanału.
Rozdzielczość czasowa misji Sentinel-2 wynosi pięć dni nad równikiem i
zwiększa się wraz ze wzrostem szerokości geograficznej, osiągając dwa
dni na średnich szerokościach geograficznych
\autocite{hejmanowska_2020_dane}.

Dane pozyskiwane przez satelity Sentinel-2 są dostępne na różnych
poziomach przetworzenia, lecz najczęściej używane przy tworzeniu map
pokrycia terenu i użytkowania ziemi (ang. \emph{Land Use/Land Cover},
LULC) są produkty 1C (współczynnik odbicia na poziomie górnej części
atmosfery; ang. \emph{Top-of-Atmospheric reflectance}, TOA) oraz 2A
(współczynnik odbicia na powierzchni Ziemi; ang.
\emph{Bottom-of-Atmospheric reflectance}, BOA)
\autocite{phiri_2020_sentinel2}.

Produkty poziomu 1C to dane poddane korekcjom radiometrycznym i
geometrycznym, prezentowane jako sceny o powierzchni 100
km\textsuperscript{2} (100 x 100 km) w projekcji UTM/WGS84
\autocite{esa_2015_sentinel2handbook}. Skuteczne wykorzystanie tych
danych w zastosowaniach związanych z terenami lądowymi wymaga
precyzyjnej korekcji zdjęć satelitarnych pod kątem efektów
atmosferycznych \autocite{main-knorn_2017_Sen2Cor}. Produkty poziomu 2A
powstają poprzez zastosowanie dodatkowej korekcji atmosferycznej dla
danych poziomu 1C za pomocą procesora korekcji atmosferycznej Sen2Cor
\autocite{main-knorn_2017_Sen2Cor}.

\hypertarget{tbl-tabela1}{}
\begin{table}
\caption{\label{tbl-tabela1}Kanały spektralne satelitów Sentinel-2 }\tabularnewline

\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{1.5cm}>{\raggedright\arraybackslash}p{4cm}>{\raggedleft\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedleft\arraybackslash}p{2cm}}
\toprule
Kanał & Nazwa kanału & Centralna długość fali [nm] & Zakres spektralny [nm] & Rozdzielczość przestrzenna [m]\\
\midrule
B01 & Coastal Aerosol & 443 & 433–453 & 60\\
B02 & Blue & 490 & 458–523 & 10\\
B03 & Green & 560 & 543–578 & 10\\
B04 & Red & 665 & 650–680 & 10\\
B05 & Vegetation RedEdge & 705 & 698–713 & 20\\
\addlinespace
B06 & Vegetation RedEdge & 740 & 733–748 & 20\\
B07 & Vegetation RedEdge & 783 & 773–793 & 20\\
B08 & NIR & 842 & 785–900 & 10\\
B8A & NIR & 865 & 855–875 & 20\\
B09 & Water Vapour & 945 & 935–955 & 60\\
\addlinespace
B10 & Cirrus & 1375 & 1360–1390 & 60\\
B11 & SWIR & 1610 & 1565–1655 & 20\\
B12 & SWIR & 2190 & 2100–2280 & 20\\
\bottomrule
\end{tabular}
\end{table}

Dane wykorzystane w analizie pochodzą z dnia 8 maja 2023 roku i zostały
dostarczone przez satelitę Sentinel-2B. Obszar analizy obejmuje kafel
(ang. \emph{tile}) o oznaczeniu 33UWV, dla którego współczynnik
zachmurzenia w tym dniu wynosił 0,7\%. Użyte zostały dane na poziomie
przetworzenia L2A. Z dostępnych kanałów spektralnych (Tabela
\ref{tbl-tabela1}) wykorzystano 10 zakresów, ponieważ pasma rejestrowane
w rozdzielczości 60 metrów są przeznaczone głównie do korekcji
atmosferycznych i detekcji chmur. Kanał 1 (443 nm) służy do korekcji
wpływu aerozoli, kanał 9 (940 nm) do korekcji wpływu pary wodnej, a
kanał 10 (1375 nm) do wykrywania chmur typu cirrus
\autocite{drusch_2012_sen2GMES}.

\hypertarget{indeksy-spektralne}{%
\subsection{Indeksy spektralne}\label{indeksy-spektralne}}

\hypertarget{tekstury-obrazu}{%
\subsection{Tekstury obrazu}\label{tekstury-obrazu}}

\hypertarget{sec-mosaics}{%
\section{Ortofotomapa i mozaiki zdjęć satelitarnych}\label{sec-mosaics}}

Do lokalizacji oraz wektoryzacji istniejących farm fotowoltaicznych
wykorzystano ortofotomapę udostępnianą przez Główny Urząd Geodezji i
Kartografii oraz mozaiki zdjęć satelitarnych dostarczane przez podmioty
komercyjne. W teledetekcji jednym z zastosowań mozaik obrazów
satelitarnych jest tworzenie zestawów danych referencyjnych poprzez
interpretację wizualną, np. w celu walidacji wyników klasyfikacji
produktów pokrycia terenu \autocite{lesiv_2018_sat_imagery_mosaics}. Do
stworzenie zbioru danych testowych i treningowych wykorzystano
ortomozaiki Google Satellite, Bing Aerial, Mapbox Satellite oraz Planet
Basemaps, udostępniane w formie usług sieciowych (WMS, WMTS, XYZ Tiles).
Ortomozaiki te są tworzone na podstawie komercyjnych zdjęć satelitarnych
wykonywanych przez podmioty takie jak Maxar Technologies, Airbus czy
Planet Labs.

Ortofotomapa udostępniana przez GUGiK charakteryzuje się rozdzielczością
przestrzenną 25 cm, a rozdzielczość przestrzenna wykorzystanych mozaik
obrazów satelitarnych (poza Planet Basemaps) jest wyższa niż 1 m, np.
dla mozaiki Bing Aerial udostępnianej przez firmę Microsoft wynosi ona
30-60 cm \autocite{ortofotomapa,bing_aerial}. Często jednak nie jest
możliwie ustalenie dat wykonania zdjęć satelitarnych, które posłużyły do
stworzenia konkretnej mozaiki zobrazowań satelitarnych
\autocite{lesiv_2018_sat_imagery_mosaics}. Mozaika tworzona przez Planet
na podstawie zdjęć satelitarnych wykonywanych przez konstelację
satelitów PlanetScope charakteryzuje się rozdzielczością przestrzenną
4,77 m na równiku, jednak w porównaniu do pozostałych wymienionych
produktów jest tworzona z miesięczną oraz kwartalną częstotliwością
\autocite{planet_2019_basemaps}. Pozwala to, pomimo niższej
rozdzielczości przestrzennej na stworzenie zbioru danych testowych i
treningowych na konkretny okres czasu. Mozaiki Planet Basemaps są
tworzone na podstawie najlepszych obrazów z katalogu Planet w określonym
przedziale czasowym. Wybierając najlepsze zdjęcia, Planet jest w stanie
tworzyć wysokorodzielcze mozaiki, które są dokładne radiometrycznie i
przestrzennie, a także charakteryzują się zminimalizowanym wpływem
czynników atmosferycznych \autocite{planet_2019_basemaps}.

?Rycina przedstawiająca jedną farmę na ortofotomapie, mozaikach
satelitarnych i scenie Sentinel-2 (kompozycja RGB)

\bookmarksetup{startatroot}

\hypertarget{sec-metody}{%
\chapter{Metody}\label{sec-metody}}

\hypertarget{sec-processing}{%
\section{Przygotowanie danych}\label{sec-processing}}

\hypertarget{sec-processing-s1}{%
\subsection{Sentinel-1}\label{sec-processing-s1}}

Korzystanie z danych radarowych wymaga wcześniejszego przygotowania
danych poprzez proces kalibracji, aby zapewnić poprawne wyniki analizy.
Procesy te mogą różnić się w zależności od konkretnego zastosowania,
mając na celu dostosowanie danych do specyficznych potrzeb. W pracy
wykorzystano schemat przetwarzania danych Sentinel-1 GRD, który
zaproponował \textcite{filipponi_2019_s1_workflow}, obejmujący:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  aktualizację danych o położeniu satelity w momencie zobrazowania
  poprzez pobranie i zastosowanie pliku orbity;
\item
  korekcję szumów termicznych;
\item
  korekcję szumów na granicach obrazów;
\item
  obliczenie współczynnika rozproszenia wstecznego (ang.
  \emph{backscatter coefficient}) sigma0 za pomocą kalibracji
  radiometrycznej;
\item
  korekcję topograficzna (ortorektyfikacja za pomocą Copernicus 30 m
  Global DEM);
\item
  konwersję współczynnika rozproszenia wstecznego na dB za pomocą
  transformacji logarytmicznej
\end{enumerate}

rycina - Sentinel-1 GRD Preprocessing Workflow

Wstępne Przetwarzanie danych dla obu wykorzystywanych polaryzacji (VV i
VH) zostało wykonane przy użyciu zestawu narzędzi ESA Sentinel-1 Toolbox
(S1TBX) \autocite{s1tbx} w oprogramowaniu SNAP \autocite{snap} przy
pomocy narzedzie do przetwarzania grafów (ang. \emph{Graph Processing
Tool}, GPT) . Kolejne etapy przygotowania danych zostały zrealizowane
przy wykorzystaniu języka R (\textcite{R-base}) oraz pakietu
\emph{terra} \autocite{R-terra}. Obszar analizy, będący kaflem
Sentinel-2 o oznaczeniu 33UWV, znajduje się na granicy dwóch sąsiednich
produktów Sentinel-1 GRD. Na potrzeby dalszego przetwarzania,
sąsiadujące produkty zostały połączone i odpowiednio ograniczone do
obszaru zainteresowania. Na granicy sąsiednich produktów Sentinel-1 GRD
występowała przestrzeń bez danych, co wymagało wypełnienia tego obszaru
danymi przy użyciu funkcji \emph{focal} z pakietu \emph{terra}.

rycina - mapa produkty S1 GRD (granice) vs.~granice kafla 33UWV
Sentinel-2

\hypertarget{sec-processing-s2}{%
\subsection{Sentinel-2}\label{sec-processing-s2}}

Przetwarzanie danych Sentinel-2 polegało na sprowadzeniu kanałów o
rozdzielczości 20 m do rozdzielczości i siatki kanałów w rozdzielczości
10 m. Przepróbkowanie (ang. \emph{resampling}) zostało przeprowadzone
przy wykorzystaniu języka R (\textcite{R-base}) oraz funkcji
\emph{resample} z pakietu \emph{terra} \autocite{R-terra}. Wykorzystano
interpolację dwuliniową (ang. \emph{bilinear interpolation}) poprzez
zastosowanie parametru \emph{method=bilinear}.

\hypertarget{sec-processing-data-merging}{%
\subsection{Łączenie danych}\label{sec-processing-data-merging}}

Resampling S1 do siatki S2. Złączenie kanałów i pozostałych danych w
wielokanałowy raster. Opisać pozostałe czynności wykonane z tymi danymi.

rycina - schemat przygotowania danych

\hypertarget{sec-samples-methods}{%
\section{Próbki treningowe i testowe}\label{sec-samples-methods}}

\hypertarget{sec-machine-learning}{%
\section{Uczenie maszynowe}\label{sec-machine-learning}}

Klasyfikacja obrazów w teledetekcji polega na grupowaniu komórek w
niewielkie zestawy klas, aby komórki w tych samych klasach miały podobne
właściwości \autocite{ismail_2009_classification}. Istnieje wiele
różnych metod klasyfikacji danych teledetekcyjnych. Stosunkowo nowymi
podejściami wykorzystywanymi w tym kontekście są metody oparte na
sztucznej inteligencji, takie jak uczenie maszynowe (ang. \emph{Machine
Learning}, ML) lub uczenie głębokie (ang. \emph{Deep Learning}, DL)
\autocite{hejmanowska_2020_dane}.

Uczenie maszynowe stanowi obszar sztucznej inteligencji, koncentrujący
się na opracowywaniu algorytmów i modeli statystycznych zapewniających
systemom komputerowym możliwość automatycznego uczenia się z danych i
wykonywania określonych zadań bez konieczności bezpośredniego
programowania. W przypadku skomplikowanych i złożonych zestawów danych
nie jesteśmy w stanie odpowiednio ich zinterpretować oraz wydobyć
poprawnych informacji po wizualnym przejrzeniu danych
\autocite{mahesh_2019_ml}. Uczenie maszynowe jest wykorzystywane do
uczenia maszyn efektywnego przetwarzania danych
\autocite{sindayigaya_2022_ml}. Algorytmy uczenia maszynowego można
podzielić na cztery główne podejścia: uczenie nienadzorowane (ang.
\emph{unsupervised learning}), uczenie nadzorowane (ang.
\emph{supervised learning}), uczenie częściowo nadzorowane (ang.
\emph{semi-supervised learning}) oraz uczenie przez wzmacnianie (uczenie
posiłkowane, ang. \emph{reinforcement learning})
\autocite{sarker_2021_ml}.

W ciągu ostaniach dwudziestu lat zaproponowano kilka różnych algorytmów
uczenia maszynowego do klasyfikacji obrazów satelitarnych
\autocite{sheykhmousa_2020_svm_vs_rf}, zazwyczaj wykorzystujące techniki
klasyfikacji bez nadzoru i klasyfikacji nadzorowanej
\autocite{ismail_2009_classification}.

Uczenie nienadzorowane analizuje nieoznakowane zbiory danych bez
konieczności ingerencji człowieka. Uczenie bez nadzoru jest powszechnie
stosowane do eksploracji danych, ekstrakcji cech generatywnych,
identyfikacji istotnych trendów i struktur oraz grupowania wyników. Ta
technika uczenia maszynowego jest najczęściej używana do grupowania
(klastowania), redukcji wielowymiarowości (redukcji cech) oraz
identyfikacji skojarzeń i relacji \autocite{sarker_2021_ml}.

Nadzorowane algorytmy uczenia maszynowego wykorzystują oznaczone dane
treningowe do znajdywania powiązań pomiędzy różnymi zmiennymi. Proces
uczenia nadzorowanego zachodzi, gdy określone cele mają zostać
osiągnięte na podstawie konkretnego zestawu danych wejściowych
(treningowych). Dwa główne typy uczenia nadzorowanego to klasyfikacja,
która separuje dane, oraz regresja, która dopasowuje dane
\autocite{sarker_2021_ml}.

W badaniu do klasyfikacji wykorzystano nadzorowaną metodę lasów losowych
(ang. \emph{Random Forest}, RF) \autocite{breiman_2001_rf}.

\hypertarget{sec-random-forest}{%
\subsection{Metoda lasów losowych}\label{sec-random-forest}}

Random Forest stał się jednym z najpopularniejszych klasyfikatorów
uczenia maszynowego wykorzystywanych przez społeczność teledetekcyjną ze
względu na dokładność jego klasyfikacji oraz wysoką wydajność
\autocite{belgiu_2016_rf,sheykhmousa_2020_svm_vs_rf}. Metoda lasów
losowych charakteryzuje się odpornością na szumy (ang. \emph{noise}) i
przeuczenie (ang. \emph{overfitting}), ponieważ nie bazuje na ważeniu
\autocite{gislason_2006_rf}.

Algorytm Random Forest, będący rozwinięciem koncepcji drzew decyzyjnych,
operuje na zasadzie ensemble learning, czyli łączenia wielu słabszych
modeli (indywidualnych drzew decyzyjnych) w jeden silniejszy model
\autocite{aaron_2018_ml,sekulic_2020_rf_interpolation}. Procedura
generuje liczne drzewa decyzyjne, opierając się na losowo wybranym
zestawie danych ze zbioru danych uczących oraz losowo wyselekcjonowanych
zmiennych klasyfikacyjnych \autocite{breiman_2001_rf}. Pojedyncze drzewo
korzysta ze zredukowanej liczby danych treningowych i zmiennych, co
sprawia, że drzewa różnią się od siebie i są mniej precyzyjne, ale
jednocześnie są też mniej skorelowane, przez co model złożony z wielu
drzew będzie bardziej niezawodny
\autocite{sekulic_2020_rf_interpolation}. W fazie predykcji każde z
drzew w lesie dokonuje prognozy, a ostateczna decyzja jest formułowana
na podstawie głosowania większościowego. W przypadku klasyfikacji, klasa
wybierana jest na podstawie największej liczby głosów.
\autocite{malinowski_2020_s2lulc}.

\hypertarget{oprogramowanie}{%
\section{Oprogramowanie}\label{oprogramowanie}}

\hypertarget{qgis}{%
\subsection{QGIS}\label{qgis}}

QGIS, dawniej Quantum GIS \autocite{qgis}, to wieloplatformowe i wolne
oprogramowanie o otwartym kodzie źródłowym przeznaczone do przetwarzania
danych przestrzennych, rozwijane przez QGIS Development Team od 2002
roku \autocite{hejmanowska_2020_dane,flenniken_2020_qgis}. Algorytmy
przetwarzania danych przestrzennych zebrane w oprogramowaniu QGIS
umożliwiają manipulację danymi rastrowymi oraz wektorowymi, a także
prowadzenie analiz i wizualizację wyników
\autocite{hejmanowska_2020_dane}. Oprogramowanie QGIS oferuje również
możliwość korzystania z wielu zewnętrznych programów, tzw. wtyczek (ang.
\emph{plug-in}) rozszerzających jego funkcjonalność
\autocite{hejmanowska_2020_dane}. W repozytorium wtyczek znaleźć można
narzędzia do zarządzania danymi, przetwarzania obrazów, wizualizacji,
czy wykonania dodatkowych zadań, takich jak np. nadawanie georeferencji
czy klasyfikacja zobrazowań satelitarnych
\autocite{hejmanowska_2020_dane}.

Oprogramowanie QGIS zostało zastosowane do stworzenia zestawu danych
referencyjnych poprzez wizualną interpretację ortofotomapy oraz mozaik
satelitarnych. QGIS dostarcza zaawansowane narzędzia do digitalizacji,
umożliwiające rysowanie i edytowanie obiektów wektorowych oraz pozwala
na przeglądanie danych przestrzennych dostępnych w Internecie za pomocą
usług sieciowych, takich jak WMS, WMTS czy XYZ Tiles.

\hypertarget{snap-i-sentinel-1-toolbox}{%
\subsection{SNAP i Sentinel-1 Toolbox}\label{snap-i-sentinel-1-toolbox}}

SNAP \autocite{snap}, czyli Sentinel Application Platform to platforma
oprogramowania rozwijana wspólnie przez firmy Brockmann Consult,
SkyWatch i C-S na zlecenie Europejskiej Agencji Kosmicznej (ESA),
przeznaczona do naukowego wykorzystania misji optycznych i mikrofalowych
Sentinel \autocite{snap-desktop,esa_snap}. Oprogramowanie SNAP zawiera
zestawy narzędzi do wizualizacji, przetwarzania oraz analizy danych
teledetekcyjnych, a zaimplementowane narzędzie do przetwarzania grafów
(ang. \emph{Graph Processing Tool}, GPT) daje możliwość tworzenia
łańcuchów procesów przetwarzania danych zdefiniowanych przez użytkownika
\autocite{hejmanowska_2020_dane,moskolai_2022_s1_workflow}. Struktura
przetwarzania grafów (ang. \emph{Graph Processing Framework}, GPF) w
oprogramowaniu SNAP służy do wsadowego przetwarzania danych za
pośrednictwem języka Extensible Markup Language (XML)
\autocite{moskolai_2022_s1_workflow}.

Przetwarzanie danych pochodzących z misji Sentinel-1 umożliwia zestaw
narzędzi S1TBX \autocite{s1tbx}, przeznaczony do przetwarzania danych
radarowych. Zestaw narzędzi Sentinel-1 Toolbox (S1TBX) zawiera narzędzia
do kalibracji, filtrowania plamek (tzw. efektu pieprzu i soli),
koregistracji, ortorektyfikacji, mozaikowania, konwersji danych,
polarymetrii i interferometrii \autocite{sentinel-1-toolbox}. Sentinel-1
Toolbox jest opracowywany dla ESA przez firmę Array we współpracy z DLR,
Brockmann Consult i OceanDataLab \autocite{sentinel-1-toolbox}.

\hypertarget{ux15brodowisko-jux119zyka-r}{%
\subsection{Środowisko języka R}\label{ux15brodowisko-jux119zyka-r}}

Czynności związane z końcowym przygotowaniem danych wejściowych oraz
bezpośrednio z uczeniem maszynowym zostały wykonane z wykorzystaniem
środowiska języka R \autocite{R-base}. R to wieloplatformowy język
programowania o otwartym kodzie źródłowym do obliczeń statystycznych i
wizualizacji danych \autocite{lovelace_2019_geocomputation}. Dzięki
dużej liczbie pakietów R obsługuje również statystki geoprzestrzenne,
modelowanie oraz wizualizację danych przestrzennych
\autocite{lovelace_2019_geocomputation}. W pracy wykorzystane zostało
zintegrowane środowisko programistyczne (ang. \emph{Integrated
Development Environment}, IDE) RStudio
\autocite{rstudio_team_2020_rstudio} przeznaczone dla języka R. Poza
standardowymi możliwościami środowiska R, w procesie pracy wykorzystane
zostały pakiety stworzone przez społeczność R w celu rozszerzenia
funkcjonalności tego języka. Do operacji na danych rastrowych
zastosowano pakiet \emph{terra} \autocite{R-terra}, natomiast do
przetwarzania danych wektorowych używany był pakiet \emph{sf}
\autocite{R-sf}. Obliczanie tekstury obrazu Sum Average wyprowadzonej z
macierzy współwystępowania poziomu szarości (ang. \emph{gray-level
co-occurrence matrix}, GLCM) zostało wykonane przy pomocy pakietu
\emph{GLCMTextures} \autocite{R-GLCMTextures}. Losowe generowanie danych
przestrzennych umożliwia pakiet \emph{spatstat.random}
\autocite{R-spatstat.random} z rodziny pakietów \emph{spatstat}
\autocite{R-spatstat}. Do przeprowadzenia analizy oraz predykcji opartej
o elementy uczenia maszynowego wykorzystano pakiet \emph{mlr3}
\autocite{R-mlr3}, w ramach którego użyty został algorytm lasów losowych
zaimplementowany w pakiecie \emph{ranger} \autocite{R-ranger}. Do
obliczeń związanych z teksturami obrazu oraz uczeniem maszynowym
wykorzystano pakiet \emph{future} \autocite{R-future}, umożliwiający
równoległe (wielowątkowe) przetwarzanie wyrażeń R, skracające czas
realizacji zadań w stosunku do przetwarzania sekwencyjnego. W funkcji
pozwalającej na równoległe obliczanie tektur obrazu wykorzystano
operator \emph{\%\textgreater\%} z pakietu \emph{dplyr}
\autocite{R-dplyr}, który daje możliwość przekazywania wyniku jednej
operacji do następnej.

\bookmarksetup{startatroot}

\hypertarget{sec-wyniki}{%
\chapter{Wyniki}\label{sec-wyniki}}

Część \textbf{Wyniki} może składać się z jednego lub więcej rozdziałów.
Każdy z tych rozdziałów powinien mieć tytuł adekwatny do swojej treści.

Rozdziały wynikowe powinny korzystać z wiedzy opisanej w poprzednich
rozdziałach (Rozdziały \ref{sec-lit}, \ref{sec-materialy},
\ref{sec-metody}). W przypadku prac analitycznych, ich treść powinna
przedstawiać kolejne etapy eksploracji i analizy danych. W przypadku
prac technicznych, treść tych rozdziałów powinna opisywać stworzone
narzędzia, a następnie pokazywać ich zastosowanie/a.

W przypadku prac technicznych warto pokazywać fragmenty napisanego
rozwiązania lub jego wywołania używając bloków kodu.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{moja\_funkcja }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(x)\{}
  \FunctionTok{cat}\NormalTok{(x, }\StringTok{"rządzi!"}\NormalTok{)}
\NormalTok{\}}
\FunctionTok{moja\_funkcja}\NormalTok{(}\StringTok{"Autor tej pracy"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Autor tej pracy rządzi!
\end{verbatim}

\bookmarksetup{startatroot}

\hypertarget{podsumowanie}{%
\chapter{Podsumowanie}\label{podsumowanie}}

Podsumowanie pracy jest w pewnym sensie znacznie rozbudowanym
abstraktem. Należy wyliczyć i opisać osiągnięcia uzyskane w pracy
dyplomowej. Tutaj jednak (w przeciwieństwie do np. rozdziału
\ref{sec-wprowadzenie}) należy przechodzić od szczegółu do ogółu - co
zostało stworzone/określone, jak zostało to zrobione, jakie ma to
konsekwencje, itd.

Ten rozdział powinien też zawierać opis kwestii, których nie udało się
rozwiązać w pracy dyplomowej (i dlaczego się nie udało) oraz pomysły na
przyszłe ulepszenie uzyskanych wyników lub dalsze badania.

\printbibliography[heading=bibintoc, title=Bibliografia]

\end{document}
