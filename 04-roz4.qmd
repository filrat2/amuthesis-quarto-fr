---
editor: 
  markdown: 
    wrap: sentence
---

# Metody {#sec-metody}

## Przygotowanie danych {#sec-processing}

### Sentinel-1 {#sec-processing-s1}

Korzystanie z danych radarowych wymaga wcześniejszego przygotowania danych poprzez proces kalibracji, aby zapewnić poprawne wyniki analizy.
Procesy te mogą różnić się w zależności od konkretnego zastosowania, mając na celu dostosowanie danych do specyficznych potrzeb.
W pracy wykorzystano schemat przetwarzania danych Sentinel-1 GRD, który zaproponował @filipponi_2019_s1_workflow, obejmujący:

1.  aktualizację informacji o położeniu satelity w momencie zobrazowania poprzez pobranie  dokładnych wektorów stanu orbity dla produktu zapewniając precyzyjne informacje o pozycji i prędkości satelity podczas akwizycji;

2.  korekcję szumów termicznych;

3.  korekcję szumów na granicach obrazów;

4.  obliczenie współczynnika rozproszenia wstecznego (ang. *backscatter coefficient*) sigma0 za pomocą kalibracji radiometrycznej;

5.  korekcję topograficzną (ortorektyfikacja za pomocą Copernicus 30 m Global DEM);

6.  konwersję współczynnika rozproszenia wstecznego na dB za pomocą transformacji logarytmicznej

```{r}
#| label: fig-rycina-s1-workflow
#| echo: false
#| fig-cap: "Przebieg wstępnego przetwarzania danych Sentinel-1 Ground Range Detected (GRD)"
#| out-width: 481px
#| out-height: 517px
knitr::include_graphics("figures/sentinel1_workflow.drawio.png")
```

Wstępne przetwarzanie danych dla obu wykorzystywanych polaryzacji (VV i VH) zostało wykonane przy użyciu zestawu narzędzi ESA Sentinel-1 Toolbox (S1TBX) [@s1tbx] w oprogramowaniu SNAP [@snap] przy pomocy narzedzie do przetwarzania grafów (ang. *Graph Processing Tool*, GPT) .
Kolejne etapy przygotowania danych zostały zrealizowane przy wykorzystaniu języka R (@R-base) oraz pakietu *terra* [@R-terra].
Obszar analizy, będący kaflem Sentinel-2 o oznaczeniu 33UWV, znajduje się na granicy dwóch sąsiednich produktów Sentinel-1 GRD. Na potrzeby dalszego przetwarzania, sąsiadujące produkty zostały połączone i odpowiednio ograniczone do obszaru zainteresowania.
Na granicy sąsiednich produktów Sentinel-1 GRD występowała przestrzeń bez danych o szerokości jednej komórki, co wymagało wypełnienia tego obszaru danymi przy użyciu funkcji *focal* z pakietu *terra*.

rycina - mapa produkty S1 GRD (granice) vs. granice kafla 33UWV Sentinel-2

### Sentinel-2 {#sec-processing-s2}

Przetwarzanie danych Sentinel-2 polegało na sprowadzeniu kanałów o rozdzielczości 20 m do rozdzielczości i siatki kanałów w rozdzielczości 10 m.
Przepróbkowanie (ang. *resampling*) zostało przeprowadzone przy *resample* z pakietu *terra* [@R-terra], stosując interpolację dwuliniową (ang. *bilinear interpolation*).

### Wskaźniki spektralne

Oprócz surowych współczynników odbicia, w niektórych wariantach predykcji zastosowano również wskaźniki spektralne (ang. *spectral indices*), które były wykorzystywane w poprzednich badaniach dotyczących detekcji farm fotowoltaicznych na podstawie danych teledetekcyjnych przez @zhang_2021_texture, @plakman_2022_pv, @wang_2022_pv i innych, takie jak:

-   znormalizowany wskaźnik roślinności (ang. *Normalized Difference Vegetation Index*, NDVI) [@ndvi], monitorujący zawartość biomasy i kondycję roślinności na danym obszarze:

    $$
    NDVI = \frac{NIR - Red}{NIR + Red}
    $$

    , gdzie $NIR$ -- reflektancja w kanale bliskiej podczerwieni, $Red$ -- reflektancja w kanale czerwonym

-   znormalizowany indeks zabudowy (ang. *Normalized Difference Built-up Index*, NDBI) [@ndbi], przeznaczony do kartowania obszarów zabudowanych:

    $$
    NDBI = \frac{SWIR1 - NIR}{SWIR1 + NIR}
    $$

    , gdzie $SWIR1$ -- reflektancja w kanale średniej podczerwieni, $NIR$ -- reflektancja w kanale bliskiej podczerwieni

-   znormalizowany indeks wody (ang. *Modified Normalized Differene Water Index*, mNDWI) [@mndwi], który skutecznie identyfikuje obszary wodne na zdjęciach satelitarnych, posiadając możliwości tłumienia zakłóceń spowodowanych przez zabudowę, roślinność i gleby:

    $$
    mNDWI = \frac{Green - SWIR1}{Green + SWIR1}
    $$

    , gdzie $Green$ -- reflektancja w kanale zielonym, $SWIR1$ -- reflektancja w kanale średniej podczerwieni

### Tekstury obrazu

Tekstura stanowi istotną cechę wykorzystywaną do identyfikacji obiektów i obszarów zainteresowania na obrazie [@haralick_1973_texture] i odgrywa ona dużą rolę w interpretacji wizualnej zdjęć lotniczych i satelitarnych [@lewinski_2012_texture].
Gdy różnice widmowe pomiędzy klasami są niewielkie, tekstura umożliwia rozróżnienie odmiennych typów obiektów na podstawie ich organizacji w terenie, często kontrastując przestrzenie naturalne z antropogenicznymi [@grass_r_texture].
W zależności od zastosowalnej funkcji wybrane cechy obrazu zostają uwidocznione w porównaniu z jego obrazem wejściowym [@lewinski_2012_texture].
Informacja o teksturze może stanowić dodatkową, przydatną zmienną wejściową w procesach klasyfikacji lub segmentacji obrazu [@gong_1992_spatial_features; @mumby_2002_ikonos].
Tekstura obejmuje różnice poziomów szarości (kontrast), obecność lub brak kierunkowości, regularne wzory i zdefiniowany obszar, na którym występują zmiany, określony przez rozmiar okna [@hall_beyer_2017_glcm; @grass_r_texture].
Można ją opisać za pomocą tonu (intensywność poziomu szarości) i struktury (relacje przestrzenne) [@grass_r_texture].
Model oparty na macierzy współwystępowania poziomów szarości (ang. *Gray Level Co-Occurrence Matrix*, GLCM), zaproponowany przez @haralick_1973_texture, jest często używany do obliczania tekstur obrazu.
Ta metoda polega na tworzeniu macierzy opisującej częstotliwość występowania par wartości w określonym fragmencie obrazu, uwzględniając określone sąsiedztwo, kierunki i odstępy między komórkami [@kupidura_2019_texture].

Przydatność i wykorzystanie tekstury w dużym stopniu zależy od rozdzielczości zdjęć satelitarnych i wielkości zjawiska, które ukształtowało teksturę [@grass_r_texture].
Badanie, które przeprowadził @zhang_2021_texture dotyczące wykorzystania filtracji teksturalnych w identyfikacji elektrowni fotowoltaicznych z użyciem Random Forest i danych z Landsata-8 wykazało pozytywny wpływ tekstur na skuteczność modelu.
Według wyników badania najlepiej dopasowany model wykorzystywał tekstury GLCM o sąsiedztwie 30 pikseli (co odpowiada wymiarom ruchomego okna o wymiarach 1800 m na 1800 m), natomiast tekstura o rozmiarze jednego sąsiada ma niewielki wpływ na poprawę dokładności modelu [@zhang_2021_texture].

Obliczanie tekstur obrazu może być czasochłonnym procesem, dlatego w pracy wykorzystano jedynie teksturę średniej sumy (ang. *Sum Average*, SA lub SAVG), wskazaną przez @wang_2022_pv jako teksturę niosącą najwięcej informacji w kontekście detekcji farm fotowoltaicznych na podstawie danych Sentinel-1, Sentinel-2 i algorytmu Random Forest.
W celu skrócenia czasu obliczeń, w pracy zdecydowano się na zastosowanie ruchomego okna o sąsiedztwie 9 komórek.

### Łączenie danych {#sec-processing-data-merging}

Rozdzielczość przestrzenna danych Sentinel-1 GRD, podobnie jak danych Sentinel-2 przegotowanych w sposób przedstawiony w podrozdziale [-@sec-processing-s2] wynosi 10 m. 
Stworzenie spójnych wielokanałowych rastrów wymaga sprowadzenia wszystkich zestawów danych do wspólnej rozdzielczości i siatki.
Dane Sentinel-1 GRD zostały przetransformowane do siatki danych Sentinel-2.
Przepróbkowane do wspólnej rozdzielczości oraz siatki dane zostały następnie użyte do obliczeń tekstur obrazu oraz wskaźników teledetekcyjnych.
Po uzyskaniu produktów pochodnych, w zależności od wariantu, dane zostały scalone w kilka wielokanałowych rastrów, które posłużyły do wyodrębnienia zestawu danych treningowych oraz do przeprowadzenia predykcji.

tabela - warianty połączenia danych - np. kanały S2, kanały S2 + indeksy spektralne, kanały S2 + polaryzacje S1 etc.

rycina - schemat przygotowania danych

## Próbki treningowe i testowe {#sec-samples-methods}

Opis wektoryzacji farm fotowoltaicznych na podstawie ortofotomapy i mozaik satelitarnych.
Opis procesu pozyskiwania próbek treningowych, uwzględniając liczbę próbek pozytywnych i negatywnych, ewentualne dobieranie negatywnych próbek z jakiejś konkretnej kategorii pokrycia terenu terenu - do napisania po ostatecznym generowaniu/losowaniu próbek

## Uczenie maszynowe {#sec-machine-learning}

Klasyfikacja obrazów w teledetekcji polega na grupowaniu komórek w niewielkie zestawy klas, aby komórki w tych samych klasach miały podobne właściwości [@ismail_2009_classification].
Istnieje wiele różnych metod klasyfikacji danych teledetekcyjnych.
Stosunkowo nowymi podejściami wykorzystywanymi w tym kontekście są metody oparte na sztucznej inteligencji, takie jak uczenie maszynowe (ang. *Machine Learning*, ML) lub uczenie głębokie (ang. *Deep Learning*, DL) [@hejmanowska_2020_dane].

Uczenie maszynowe stanowi obszar sztucznej inteligencji, koncentrujący się na opracowywaniu algorytmów i modeli statystycznych zapewniających systemom komputerowym możliwość automatycznego uczenia się z danych i wykonywania określonych zadań bez konieczności bezpośredniego programowania.
W przypadku skomplikowanych i złożonych zestawów danych nie jesteśmy w stanie odpowiednio ich zinterpretować oraz wydobyć poprawnych informacji po wizualnym przejrzeniu danych [@mahesh_2019_ml].
Uczenie maszynowe jest wykorzystywane do uczenia maszyn efektywnego przetwarzania danych [@sindayigaya_2022_ml].
Algorytmy uczenia maszynowego można podzielić na cztery główne podejścia: uczenie nienadzorowane (ang. *unsupervised learning*), uczenie nadzorowane (ang. *supervised learning*), uczenie częściowo nadzorowane (ang. *semi-supervised learning*) oraz uczenie przez wzmacnianie (uczenie posiłkowane, ang. *reinforcement learning*) [@sarker_2021_ml].

W ciągu ostaniach dwudziestu lat zaproponowano kilka różnych algorytmów uczenia maszynowego do klasyfikacji obrazów satelitarnych [@sheykhmousa_2020_svm_vs_rf], zazwyczaj wykorzystujące techniki klasyfikacji bez nadzoru i klasyfikacji nadzorowanej [@ismail_2009_classification].

Uczenie nienadzorowane analizuje nieoznakowane zbiory danych bez konieczności ingerencji człowieka.
Uczenie bez nadzoru jest powszechnie stosowane do eksploracji danych, ekstrakcji cech generatywnych, identyfikacji istotnych trendów i struktur oraz grupowania wyników.
Ta technika uczenia maszynowego jest najczęściej używana do grupowania (klastowania), redukcji wielowymiarowości (redukcji cech) oraz identyfikacji skojarzeń i relacji [@sarker_2021_ml].

Nadzorowane algorytmy uczenia maszynowego wykorzystują oznaczone dane treningowe do znajdywania powiązań pomiędzy różnymi zmiennymi.
Proces uczenia nadzorowanego zachodzi, gdy określone cele mają zostać osiągnięte na podstawie konkretnego zestawu danych wejściowych (treningowych).
Dwa główne typy uczenia nadzorowanego to klasyfikacja, która separuje dane, oraz regresja, która dopasowuje dane [@sarker_2021_ml].

W poniższym badaniu do klasyfikacji wykorzystano nadzorowaną metodę lasów losowych (ang. *Random Forest*, RF) [@breiman_2001_rf].

### Metoda lasów losowych {#sec-random-forest}

Random Forest stał się jednym z najpopularniejszych klasyfikatorów uczenia maszynowego wykorzystywanych przez społeczność teledetekcyjną ze względu na dokładność jego klasyfikacji oraz wysoką wydajność obliczeniową [@belgiu_2016_rf; @sheykhmousa_2020_svm_vs_rf].
Metoda lasów losowych charakteryzuje się pewną odpornością na szumy (ang. *noise*) i przeuczenie (ang. *overfitting*), ponieważ nie bazuje na ważeniu [@gislason_2006_rf].

Algorytm Random Forest, będący rozwinięciem koncepcji drzew decyzyjnych, operuje na zasadzie uczenia zespołowego (ang. *ensemble learning*), czyli łączenia wielu słabszych modeli (indywidualnych drzew decyzyjnych) w jeden silniejszy model [@aaron_2018_ml; @sekulic_2020_rf_interpolation].
Procedura generuje liczne drzewa decyzyjne, opierając się na losowo wybranym zestawie danych ze zbioru danych uczących oraz losowo wyselekcjonowanych zmiennych klasyfikacyjnych [@breiman_2001_rf].
Pojedyncze drzewo korzysta ze zredukowanej liczby danych treningowych i zmiennych, co sprawia, że drzewa różnią się od siebie i są mniej dokładne, ale jednocześnie są też mniej skorelowane, przez co model złożony z wielu drzew będzie bardziej niezawodny [@sekulic_2020_rf_interpolation].
W fazie predykcji każde z drzew w lesie dokonuje prognozy, a ostateczna decyzja jest formułowana na podstawie głosowania większościowego. 
W przypadku klasyfikacji, klasa wybierana jest na podstawie największej liczby głosów. [@breiman_2001_rf].

## Oprogramowanie

### QGIS

QGIS [@qgis], to wieloplatformowe i wolne oprogramowanie o otwartym kodzie źródłowym przeznaczone do przetwarzania danych przestrzennych, rozwijane od 2002 roku [@hejmanowska_2020_dane; @flenniken_2020_qgis].
Algorytmy przetwarzania danych przestrzennych zebrane w oprogramowaniu QGIS umożliwiają manipulację danymi rastrowymi oraz wektorowymi, a także prowadzenie analiz i wizualizację wyników [@hejmanowska_2020_dane].
Oprogramowanie QGIS oferuje również możliwość korzystania z wielu zewnętrznych programów, tzw.
wtyczek (ang. *plug-in*) rozszerzających jego funkcjonalność [@hejmanowska_2020_dane].
W repozytorium wtyczek znaleźć można narzędzia do zarządzania danymi, przetwarzania obrazów, wizualizacji, czy wykonania dodatkowych zadań, takich jak np.
nadawanie georeferencji czy klasyfikacja zobrazowań satelitarnych [@hejmanowska_2020_dane].

Oprogramowanie QGIS zostało wykorzystane w tej pracy do stworzenia zestawu danych referencyjnych poprzez wizualną interpretację ortofotomapy oraz mozaik satelitarnych.
QGIS dostarcza zaawansowane narzędzia do digitalizacji, umożliwiające rysowanie i edytowanie obiektów wektorowych oraz pozwala na przeglądanie danych przestrzennych dostępnych w Internecie za pomocą usług sieciowych, takich jak WMS, WMTS czy XYZ Tiles.

### Sentinel-1 Toolbox i SNAP

Przetwarzanie danych pochodzących z misji Sentinel-1 umożliwia zestaw narzędzi S1TBX [@s1tbx], przeznaczony do przetwarzania danych radarowych.
Zestaw narzędzi Sentinel-1 Toolbox (S1TBX) zawiera narzędzia do kalibracji, filtrowania plamek (tzw. efektu pieprzu i soli), koregistracji, ortorektyfikacji, mozaikowania, konwersji danych, polarymetrii czy interferometrii [@sentinel-1-toolbox].
Sentinel-1 Toolbox jest opracowywany dla ESA przez firmę Array we współpracy z DLR, Brockmann Consult i OceanDataLab [@sentinel-1-toolbox].

SNAP [@snap], czyli Sentinel Application Platform to platforma oprogramowania rozwijana wspólnie przez firmy Brockmann Consult, SkyWatch i C-S na zlecenie Europejskiej Agencji Kosmicznej (ESA), przeznaczona do naukowego wykorzystania misji optycznych i mikrofalowych Sentinel [@snap-desktop; @esa_snap].
Oprogramowanie SNAP zawiera zestawy narzędzi do wizualizacji, przetwarzania oraz analizy danych teledetekcyjnych, a zaimplementowane narzędzie przetwarzania grafów (ang. *Graph Processing Tool*, GPT) daje możliwość tworzenia łańcuchów procesów przetwarzania danych zdefiniowanych przez użytkownika [@hejmanowska_2020_dane; @moskolai_2022_s1_workflow].
Struktura przetwarzania grafów (ang. *Graph Processing Framework*, GPF) w oprogramowaniu SNAP służy do wsadowego przetwarzania danych za pośrednictwem języka Extensible Markup Language (XML) [@moskolai_2022_s1_workflow].

### Środowisko języka R

Czynności związane z końcowym przygotowaniem danych wejściowych oraz bezpośrednio z uczeniem maszynowym zostały wykonane z wykorzystaniem środowiska języka R [@R-base].
R to wieloplatformowy język programowania o otwartym kodzie źródłowym do obliczeń statystycznych i wizualizacji danych.
Dzięki dużej liczbie pakietów R obsługuje również statystki geoprzestrzenne, modelowanie oraz wizualizację danych przestrzennych [@lovelace_2019_geocomputation].
W pracy wykorzystane zostało zintegrowane środowisko programistyczne (ang. *Integrated Development Environment*, IDE) RStudio [@rstudio_team_2020_rstudio] przeznaczone dla języka R.
Poza standardowymi możliwościami środowiska R, w procesie pracy wykorzystane zostały pakiety stworzone przez społeczność R w celu rozszerzenia funkcjonalności tego języka.
Do operacji na danych rastrowych zastosowano pakiet *terra* [@R-terra], natomiast do przetwarzania danych wektorowych używany był pakiet *sf* [@R-sf].
Obliczanie tekstury obrazu Sum Average wyprowadzonej z macierzy współwystępowania poziomu szarości (ang. *gray-level co-occurrence matrix*, GLCM) zostało wykonane przy pomocy pakietu *GLCMTextures* [@R-GLCMTextures].
Losowe generowanie danych przestrzennych umożliwił pakiet *spatstat.random* [@R-spatstat.random] z rodziny pakietów *spatstat* [@R-spatstat].
Do przeprowadzenia analizy oraz predykcji opartej o elementy uczenia maszynowego wykorzystano pakiet *mlr3* [@R-mlr3], w ramach którego użyty został algorytm lasów losowych zaimplementowany w pakiecie *ranger* [@R-ranger].
Do obliczeń związanych z teksturami obrazu oraz uczeniem maszynowym wykorzystano pakiet *future* [@R-future], umożliwiający równoległe (wielowątkowe) przetwarzanie wyrażeń R, skracające czas realizacji zadań w stosunku do przetwarzania sekwencyjnego.

```{r}
#| label: pakietbib
#| echo: false
#| warning: false
pakiety = c("base", "terra", "sf", "GLCMTextures", "spatstat.random", "spatstat", "mlr3", "ranger", "future")
knitr::write_bib(pakiety, "packages.bib", width = 60)
```
