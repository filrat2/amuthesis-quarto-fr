# Wyniki {#sec-wyniki}

<!--
Część **Wyniki** może składać się z jednego lub więcej rozdziałów. 
Każdy z tych rozdziałów powinien mieć tytuł adekwatny do swojej treści.

Rozdziały wynikowe powinny korzystać z wiedzy opisanej w poprzednich rozdziałach (Rozdziały [-@sec-lit], [-@sec-materialy], [-@sec-metody]).
W przypadku prac analitycznych, ich treść powinna przedstawiać kolejne etapy eksploracji i analizy danych.
W przypadku prac technicznych, treść tych rozdziałów powinna opisywać stworzone narzędzia, a następnie pokazywać ich zastosowanie/a.

W przypadku prac technicznych warto pokazywać fragmenty napisanego rozwiązania lub jego wywołania używając bloków kodu.

```{r}
moja_funkcja = function(x){
  cat(x, "rządzi!")
}
moja_funkcja("Autor tej pracy")
```
-->

## Ocena jakości modeli {#sec-results-model-quality-assessment}

Dla każdego z sześciu wariantów zestawów danych wskazanych w tabeli [-@tbl-tabela-datasets] przeprowadzono osobną zagnieżdżoną *k*-krotną przestrzenną walidację krzyżową, zgodnie z sekcją [-@sec-model-quality-assessment].
Zagnieżdżona przestrzenna walidacja krzyżowa dla jednego wariantu składała się z kilku etapów, obejmujących optymalizację hiperparametrów oraz ocenę jakości.

Proces strojenia został skonfigurowany tak, aby generować 1 000 modeli dla jednego foldu w celu określenia optymalnych hiperparametrów.
Powtarzając tę procedurę dla każdego z pięciu ustalonych foldów, uzyskano łącznie 5 000 modeli w ramach jednego powtórzenia.
W celu identyfikacji optymalnych hiperparametrów założono dwadzieścia iteracji wymienionych powyżej działań, co doprowadziło do stworzenia łącznie 100 000 modeli.

Zoptymalizowane parametry modelu zostały następnie wykorzystane do oszacowania jakości modelu, co wymagało dopasowania dodatkowych 100 modeli (5 foldów * 20 powtórzeń).
W rezultacie całkowita liczba stworzonych modeli wykorzystanych do oceny jakości i dostrajania hiperparametrów dla jednego wariantu wynosi 100 100.

```{r tabela1, echo=FALSE}
#| label: tbl-tabela-performance-measures
#| echo: false
#| tbl-cap: "Śrdenie wyniki oceny jakości modeli uzyskane podczas przestrzennej walidacji krzyżowej"
df = readRDS("C:/Users/Filip/Desktop/inzynierka/rds/performance_scores_df_12_01.rds")
rownames(df) = gsub("classif.", '', rownames(df))
colnames(df) = gsub('dataset', 'Dataset ', colnames(df))
rownames(df)[4] = "AUC"
rownames(df)[5] = "F-beta score"
kableExtra::kable(df, align = "c", booktabs = TRUE, digits = 4, linesep = "")
```

Ocenę klasyfikatorów stworzonych dla każdego z sześciu wariantów (tabela [-@tbl-tabela-datasets]) przeprowadzono przy użyciu pięciu miar jakości opisanych w sekcji [-@sec-model-quality-assessment].
Średnie wyniki miar jakości modeli oszacowane na podstawie przestrzennej walidacji krzyżowej przedstawia tabela [-@tbl-tabela-performance-measures].

Ogólnie średnie wartości miar jakości dla każdego z wariantów są zbliżone.
Prawdopodobnie wynika to z faktu, że w każdym wariancie dziesięć klasyfikatorów uwzględniało dane dotyczące reflektancji Sentinel-2 w poszczególnych kanałach.
Każdy wariant różnił się jednak od pozostałych zestawem dodatkowych zmiennych.

Na podstawie średnich wartości miar jakości przedstawionych w tabeli [-@tbl-tabela-performance-measures], najlepsze dopasowanie uzyskano, wykorzystując wszystkie predyktory (wariant nr 6).
Ten wariant osiągnął najwyższe średnie oceny w czterech z pięciu zastosowanych miar (precyzja, specyficzność, AUC i $F_{\beta}$ score).
Najlepszy wynik czułości uzyskał natomiast wariant nr 1.
W przypadku trzech z pięciu miar najniższe wyniki odnotowano dla wariantu nr 3 (precyzja, specyficzność i $F_{\beta}$ score).
Najgorszą czułością cechuje się natomiast wariant nr 5, a najniższym wynikiem miary AUC - wariant nr 4.

Średnie wyniki czułości i miary AUC dla wszystkich klasyfikatorów są bardzo zbliżone, a różnice pomiędzy najlepszym a najgorszym wynikiem są niewielkie.
Rozrzut pomiędzy najlepszym a najgorszym wynikiem dla precyzji wynosi 0,0434, dla czułości 0,0332, a dla $F_{\beta}$ score 0,0238, co wskazuje na bardziej znaczące różnice.
Średnie wyniki precyzji czterech z sześciu klasyfikatorów przekroczyły wartość 0,90 (0,8746 dla najgorszego wariantu nr 3, 0,9180 dla najlepszego wariantu nr 6).
Klasyfikatory wzorowo radziły sobie w wykrywaniu ujemnych wyników (True negative), uzyskując bardzo wysokie wyniki specyficzności (zakres wartości od 0,9924 do 0,9956).
Niższe wyniki czułości wskazują jednak na mniej efektywne radzenie sobie z wykrywaniem wyników dodatnich (True positive). 
Wszystkie klasyfikatory uzyskały wyniki czułości na poziomie wyższym niż 0,70, kształtując się w zakresie od 0,7081 do 0,7413.
Podobnie jak w przypadku specyficzności, wszystkie klasyfikatory uzyskały wysokie oceny dla miary AUC, gdzie najgorszy wynik wyniósł 0,9802, a najlepszy 0,9867.
Wyniki miary $F_{\beta}$ score dla każdego wariantu przekroczyły wartość 0,75, mieszcząc się w zakresie pomiędzy 0,7691, a 0,7929.

## Ważność zmiennych {#sec-results-variable-importance}

```{r}
#| label: fig-rycina-variance-importance_cowplot
#| echo: false
#| fig-cap: "Permutowane znaczenie 10 najważniejszych zmiennych dla każdego wariantu"
#| out-width: 105%
knitr::include_graphics("figures/importance_cowplot.png")
```

Dla każdego z sześciu wariantów (tabela [-@tbl-tabela-datasets]) przeprowadzono ocenę ważności zmiennych z wykorzystaniem metody opartej na permutacji, szczegółowo opisanej w sekcji [-@sec-variable-importance].
Ważność zmiennych dla każdego wariantu została posortowana w porządku malejącym i przedstawiona na rycinie [-@fig-rycina-variance-importance_cowplot], która prezentuje moc predykcyjną różnych zmiennych wejściowych.
Na potrzeby wizualizacji przedstawiono 10 najważniejszych zmiennych dla każdego wariantu, co odpowiada liczbie predyktorów w wariancie o najmniejszej ilości zmiennych (wariant nr 1).
Rycina [-@fig-rycina-variance-importance-dataset6] ilustruje permutowaną ważność zmiennych dla wariantu nr 6, obejmującego wszystkie dostępne zmienne (21 predyktorów).

```{r}
#| label: fig-rycina-variance-importance-dataset6
#| echo: false
#| fig-cap: "Permutowana ważność zmiennych dla wariantu nr 6"
#| out-width: 450px
knitr::include_graphics("figures/importance_plot_dataset6.png")
```

Pomijając aspekt związków i interakcji pomiędzy zmiennymi, które powodowały subtelne różnice w kolejności znaczenia zmiennych dla poszczególnych wariantów, zauważalny jest podział zmiennych na pięć grup według ich istotności w detekcji farm fotowoltaicznych.
Z rycin [-@fig-rycina-variance-importance_cowplot] i [-@fig-rycina-variance-importance-dataset6] wynika, że największe znaczenie spośród wszystkich predyktorów miała grupa czterech zmiennych: tekstura średniej sumy kanału niebieskiego (B02 SAVG), kanały średniej podczerwieni (SWIR1 (B11) i SWIR2 (B12)) oraz kanał niebieski (B02).
Trochę niższą istotność w kontekście wykrywania farm fotowoltaicznych miały trzy kolejne zmienne: znormalizowany zmodyfikowany różnicowy wskaźnik wody (mNDVI), znormalizowany różnicowy wskaźnik obszarów zabudowanych (NDBI) oraz kanał czerwony (B04).
Trzecią grupę stanowiły dwie zmienne: znormalizowany różnicowy wskaźnik wegetacji (NDVI) oraz jeden z kanałów czerwieni krawędziowej (tzw. *RedEdge*, B05), a do czwartej grupy zaliczyć można tekstury średniej sumy dla polaryzacji VV i wskaźnika mNDWI (VV SAVG, mNDWI SAVG) oraz kanał bliskiej podczerwieni (B8A).
Najmniejsze znaczenie przy detekcji farm fotowoltaicznych miały kanał zielony (B03), pozostałe kanały czerwieni krawędziowej (B06 i B07),  kanał bliskiej podczerwieni (B08), obie wykorzystane polaryzacje (VV i VH) oraz tekstury średniej sumy dla kanału B8A, polaryzacji VH oraz wskaźnika NDBI (B8A SAVG, VH SAVG i NDBI SAVG).

Uzyskane wyniki oceny ważności zmiennych wskazują na dość spore znacznie wskaźników spektralnych, głównie mNDWI oraz NDBI w kontekście wykrywania farm fotowoltaicznych.
Niskie znaczenie w tym zastosowaniu wykazują natomiast dane radarowe pochodzące z misji Sentienl-1 oraz tekstury średniej sumy dla tych zmiennych.

Spośród sześciu obliczonych tekstur średniej sumy wskazanych przez @wang_2022_pv jako istotne przy detekcji farm fotowoltaicznych na podstawie danych Sentinel-1, Sentinel-2 i algorytmu Random Forest, jedynie tekstura średniej sumy dla kanału niebieskiego wykazywała się znaczącym wpływem na wynik klasyfikacji.
Pozostałe tekstury wskazywały przeciętną lub niską istotność w tym konkretnym zadaniu.
Ważność trzech z obliczonych tekstur (B02 SAVG, VV SAVG i VH SAVG) była wyższa niż ocena ważności odpowiadających im danych pierwotnych.
W przypadku pozostałych trzech tekstur (B8A SAVG, mNDWI SAVG i NDBI SAVG), uzyskane wyniki były niższe niż wyniki pierwotnych danych teledetekcyjnych.

**W tym miejscu można też wstawić rycinę (corplot) z korelacją między zmiennymi oraz/lub rycinę z krzywymi spektralnymi dla różnych klas pokrycia terenu, w tym farm fotowoltaicznych. Można także rozważyć umieszczenie tych rycin w sekcji [-@sec-variable-importance].**

## Wyniki klasyfikacji {#sec-classification-results}

### Przestrzenna ocena jakości predykcji {#sec-spatial-quality-assessment}



### Wizualna kontrola wyników klasyfikacji {#sec-visual-quality-assessment}

Zgodnie z sekcją dotyczącą przestrzennej oceny jakości (sekcja [-@sec-spatial-quality-assessment]), modele stworzone w ramach niniejszego badania wykazują dobrą skuteczność w identyfikacji farm fotowoltaicznych, co ilustruje również rycina [-@fig-rycina-truepositive-dataset6], przedstawiająca przykłady poprawnych przewidywań dla wariantu nr 6.
Dla porównania, na rycinie przedstawiono także instalacje fotowoltaiczne generujące energię elektryczną, pochodzące z badania przeprowadzonego przez @kruitwagen_2021_pv, wskazującego istniejące konstrukcje fotowoltaiczne na świecie na dzień 30 września 2018 roku.
Wysokorozdzielcze obrazy satelitarne na rycinie [-@fig-rycina-truepositive-dataset6] (kolumna a) pochodzą z różnych okresów.
Obraz satelitarny 2a został pozyskany później niż dane użyte do detekcji farm fotowoltaicznych w niniejszym badaniu (8 maja 2023 roku), natomiast obrazy 4a i 4b pochodzą sprzed tego okresu.

W niektórych przypadkach wewnątrz wykrytych instalacji fotowoltaicznych pojawiły się fałszywie ujemne predykcje (ang. *False negative*), co przedstawiają ryciny [-@fig-rycina-truepositive-dataset6] 1c i [-@fig-rycina-post-processing] 2c.
Na kompozycji RGB Sentinel-2 możemy zaobserwować w miejscach tych błędnych wskazań różnice w jasności komórek względem otaczającej instalacji fotowoltaicznej lub zróżnicowanie powierzchni pod panelami fotowoltaicznymi.
Rycina [-@fig-rycina-truepositive-dataset6] 5c pokazuje, że w niektórych przypadkach poprawne wskazania powierzchni farm fotowoltaicznych są niepełne, pomimo jednolitego wyglądu instalacji na kompozycji RGB Sentinel-2.

Problemem stworzonych modeli jest ich tendencja do przeuczania się na niektórych typach pokrycia terenu i użytkowania ziemi, co zostało szerzej opisane w sekcji dotyczącej losowania próbek (sekcja [-@sec-samples]).
Zaproponowane metody przetwarzania końcowego, omówione w sekcji [-@sec-post-processing], poprawiają wyniki predykcji.
Niemniej jednak, w zależności od wariantu, nadal występują mniejsze lub większe błędy w klasyfikacji.
Przykłady fałszywie dodatnich przewidywań (ang. *False positive*) zostały przedstawione na rycinach [-@fig-rycina-falsepositive-dataset6] (dla wariantu nr 6) oraz [-@fig-rycina-post-processing] (dla wariantu nr 1).
Wybrane lokalizacje ilustrują typowe błędy modeli na różnych typach pokrycia terenu i użytkowania ziemi.

Mimo zastosowania dodatkowych próbek negatywnych na drogach oraz kopalniach torfu, jak wskazano w sekcji [-@sec-samples], błędne pozytywne przewidywania na tych obszarach nadal występują, co ilustrują odpowiednio pierwszy i czwarty rząd ryciny [-@fig-rycina-falsepositive-dataset6].
Trzeci rząd ryciny [-@fig-rycina-falsepositive-dataset6] oraz drugi rząd ryciny [-@fig-rycina-post-processing] sugerują, że błędne predykcje mogą występować również na obszarach zachmurzonych.
Drugi rząd ryciny [-@fig-rycina-falsepositive-dataset6] oraz pierwszy rząd ryciny [-@fig-rycina-post-processing] pokazują natomiast, że błędne predykcje obejmują także obszary użytków rolnych (pola uprawne, łąki i pastwiska) oraz nieużytków, szczególnie w miejscach, gdzie istnieje gęsta sieć melioracyjna.
W wyniku klasyfikacji wariantu nr 6 pojawił się nietypowy przypadek błędnego sklasyfikowania boiska sportowego jako instalacji fotowoltaicznej, które ze względu na powierzchnię większą niż 1000 m^2^ nie zostało skorygowane przez zastosowane metody przetwarzania końcowego.

Należy zaznaczyć, że pomimo wykorzystania próbek z tych samych lokalizacji do trenowania każdego z wariantów, różne modele wykazują zróżnicowaną skuteczność klasyfikacji w zależności od typów pokrycia terenu i użytkowania ziemi.
Jest to prawdopodobnie rezultat wpływów różnych zmiennych, gdzie niektóre z nich wspomagały decyzje w przypadku konkretnego typu pokrycia terenu, podczas gdy inne miały przeciwny efekt.

**DO WNIOSKÓW: Wizualna kontrola obszarów wskazanych na rycinach potwierdziła, że modele w większości przepadków skutecznie dokonują rozróżnienia farm fotowoltaicznych i pozostałych obszarów podczas klasyfikacji. Niemniej jednak, w wynikach predykcji pojawiło się kilka powtarzających się błędów. W celu poprawy wyników identyfikacji farm fotowoltaicznych, zaleca się zastosowanie masek do eliminacji obszarów chmur i ich cieni. Dodatkowo, warto rozważyć wprowadzenie dodatkowego etapu w procesie przetwarzania końcowego, który wykluczałby predykcje wzdłuż dróg na podstawie danych z OpenStreetMap (OSM), zgodnie z sugestią Ortiz et al. (2022).**


```{r}
#| label: fig-rycina-truepositive-dataset6
#| echo: false
#| fig-cap: "Wyniki klasyfikacji wariantu nr 6 po procesie przetwarzania końcowego. Porównanie przykładów prawdziwie dodatnich przewidywań (ang. True positive) (c) z wysokorozdzielczymi obrazami satelitarnymi (a) oraz kompozycją RGB Sentinel-2 (b)"
#| out-width: 91%
knitr::include_graphics("figures/pv_dataset6.png")
```

```{r}
#| label: fig-rycina-falsepositive-dataset6
#| echo: false
#| fig-cap: "Wyniki klasyfikacji wariantu nr 6 po procesie przetwarzania końcowego. Porównanie przykładów fałszywie dodatnich przewidywań (ang. False positive) (c) z wysokorozdzielczymi obrazami satelitarnymi (a) oraz kompozycją RGB Sentinel-2 (b)"
#| out-width: 91%
knitr::include_graphics("figures/incorrect_dataset6.png")
```
